              
                %% bare_jrnl.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/


% Please refer to your journal's instructions for other
% options that should be set.
\documentclass[journal,onecolumn]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage{amsmath}
\usepackage{amssymb}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.

\usepackage{makecell}



% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Stage 0: Robust Deep Learning for Music Performance Analysis}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Vinod Subramanian, QMUL, ROLI Ltd.}% <-this % stops a space


% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers

% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2015 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
The abstract goes here.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
MIR
\end{IEEEkeywords}






% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}

% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.

Music performance analysis can be simply defined as understanding specific features of the music in order to assess it for a specific purpose. A student might want to analyze a professional recording to understand better playing technique and  rhythm accuracy, a streaming service company might want to analyze music to create tags to help users browse through music easily, a music production company might want to organize sounds based on timbral similarity and pitch etc. So we can see that music performance analysis is of importance and there is a breadth of features that would help with the analysis of the music.

In this PhD we want to focus on deep learning approaches towards learning these features. Research in the field of music information retrieval (MIR) has shown that deep learning is a good alternative to hand crafted features. As the field of deep learning in MIR matures we have an increasing number of new model architectures on the new datasets. This increase in new models and datasets makes it harder to compare which model is better.  

One of the biggest challenges of deep learning that remains today is the interpretability of the features being learned. Due to the non-linearity and complexity of these models it is not a simple task to understand exactly what is being learned. While we can study saliency maps to identify what neurons are being activated, it is still unclear as to what features are being learned exactly even when the model is performing really well.

The fact that there is lack of understanding of the underlying features poses the concern of how well can we trust the output of the system. Recent research \cite{szegedy_intriguing_2013} \cite{goodfellow_explaining_2014} has shown that it is possible to fool the classifier into misclassifying the input by applying an imperceptible non-random values to it. This exposed the vulnerability of deep learning and quickly became a popular area of research in security and privacy of image recognition algorithms. 

In music applications adversarial examples could pose a challenge in terms of identifying copyrighted content on websites. 

The more general conclusions that can be drawn from \cite{szegedy_intriguing_2013} and \cite{goodfellow_explaining_2014} is that deep learning models are not learning high level features as well as we expect them too. So by using the techniques described in these papers we can indirectly determine whether deep learning models are learning high level features in way that we expect them to. 

The original title for this project was 'Note level features for music performance analysis and visualization'. We will go through each part of this title and explain how it is related to robust deep learning and tied to the MIP-frontiers broader interest of research that gives back to the citizens of the European Union. Note level features include features such as pitch, onsets, playing technique, timbre etc. The purpose of these note level features is to capture the musical performance and transform them or generate new performances.

These different note level features have already been studied in detail from signal processing to deep learning approaches. Before we start suggesting new deep learning methods that will improve the accuracy of these models on some dataset we want to understand if the features being learned are meaningful and understand how to develop a new system that captures features that are more musically meaningful. By using this work flow to create new deep learning models we hope to create more robust deep learning systems.

We have listed many different types of MIR tasks which we are going to classify as follows:



\begin{enumerate}
\item Talk about how it is important for copyright
\item Important for more robust models
\item Talk about original title of this project and how it evolved
\item Classification of MIR tasks
\item summary of rest of paper
\end{enumerate}

 

	
% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)

\section{Background}


\subsection{What are adversarial attacks?}
Szegedy et al. \cite{szegedy_intriguing_2013} discovered that in object recognition tasks by applying an imperceptible non-random perturbation to the input image the output of the network can be changed. The term "Adversarial examples" is used to describe these perturbed examples. These adversarial examples were attributed to the fact that there are blindspots in the training process for these deep learning models. %Add image examples to demonstrate point

Goodfellow, Shlens and Szegedy \cite{goodfellow_explaining_2014} challenged the idea that adversarial examples were due to blind spots in high dimensional spaces. Instead, they suggested that they are caused due to linearity in deep learning models. According to them LSTMS, ReLUs, maxout networks, CNNs etc. were intentiaonally designed to behave more linearly in order to make them easier to optimize. %Cite LSTMS, ReLUs and maxout

Assume we have a linear classifier defined by the relationship $y = f(x)$ where $f(x)$ is given by $f(x) = \omega^{T}x$. Our goal is to perturb the input $x$ with perturbation $\eta$ subject to the condition that $D(x+\eta,x)<\epsilon$ where $D$ is some distance measure. We can write the new equation for the ouput of the classifier as:

\begin{equation}
\tilde{y} = \omega^{T}x + \omega^{T}\eta
\end{equation}

By choosing $\eta$ carefully so that it is aligned in the direction of the weights of the classifier $\omega$ the change in the output can be maximized. 

Goodfellow, Shlens and Szegedy \cite{goodfellow_explaining_2014} used this formulation for linear classifiers on deep learning models and came up with a family of fast gradient approaches to generate adversarial examples. The fact that they were able to generate adversarial examples by treating deep learning models as linear classifiers was used to support the argument that deep learning algorithms are too linear.

Before we give more details about different types of adversarial attacks and defenses against these attacks we'll list the different categories of adversarial attacks. The category of an adversarial attack is determined by either the goal of the adversary or the information the adversary has of the classifier.

Goal of the adversary:
\begin{enumerate}
\item Untargeted attack - The adversary's goal is to simply misclassify the input. As long as the new target class of the classifier is different from the original the adversary has achieved its goal.
\item Targeted attack - The adversary's goal is to change the label from the original to a different label that is specified before the attack begins. Because there are more constraints in the targeted attack it is typically harder to generate targeted adversarial examples as opposed to untargeted adversarial examples.
\end{enumerate}

Information of the adversary:
\begin{enumerate}
\item Perfect knowledge - In this scenario the adversary has perfect knowledge of the classifier such as the feature space, the weights of the model and the type of classifier. This is also known as a white box attack.
\item Limited knowledge - The classifier does not know the training data or the trained model but has knowledge about the feature representation and the type of classifier. This could be considered a black box attack.
\item Zero knowledge - This is a special case where an adversarial example is generated for one classifier and then tested on a different classifier which it has no information about.
\end{enumerate}

In the following sections I will introduce different techniques for attacks, different techniques for defenses and some unique properties of adversarial attacks such as universal perturbation, transferability of adversarial examples and adversarial examples in the real world. Finally I will highlight the existing body of work that explores adversarial attacks in audio and talk about existing deep learning tasks in music information retrieval (MIR) that would be a good starting point for research into adversarial attacks in music.


\subsection{Summary of attacks}

\begin{enumerate}
\item L-BFGS - Szegedy et al. \cite{szegedy_intriguing_2013} introduced one of the first methods for generating adversarial attacks, it is a white box attack that is targeted.

Assume a classifier denoted as $f : \mathbb{R}^m \rightarrow \{1...k\} $ with a loss function $loss_f$. For a given input $x \in \mathbb{R}^m$ and target $t \in \{1....k\}$ we aim to identify the value of perturbation $r$ as formulated below:
\begin{align*}
&  \text{Minimize  $\Vert r \Vert_2$ under the conditions:}\\
& f(x+r)= t \\
& x+r\in [0,1]^m
\end{align*}

The exact computation of this problem is difficult so it is approximated using the box constrained L-BFGS algorithm. So the new equation to minimize is:
\begin{align*}
c \vert r \vert + loss_f(x+r,l) && \text{under the conditions $x+r \in [0,1]^m$}
\end{align*}

\item Fast Gradient Sign Method - The goal of this method is to quickly generate a simple adversarial examples. By perturbing the input in the direction of the gradient of the weights of the model by a sufficient amount it can create an adversarial example \cite{goodfellow_explaining_2014}. Let $x$ be the input to the model and $y$ be the output, the model parameters are $\theta$. The cost function of the model is $J(\theta,x,y)$. With this information we can create an adversarial example by computing the perturbation $\eta$ using the formula:

\begin{equation}
\eta = \epsilon sign(\triangledown_x J(\theta,x,y))
\end{equation}

In this equation $\epsilon$ is decided manually until the formula causes a perturbation. This technique was refined by making the process iterative and computing the gradient repeatedly and showed improved results.

\item Jacobian based Saliency Map Attack (JSMA) - Papernot et al. \cite{papernot_limitations_2015} introduced a white box attack which requires knowledge of the model parameters but does not require knowledge of the training data, it is a targeted attack. The goal of the algorithm is to identify the pixels in the input that impact the output the most and perturb these important pixels to change the output to the target output. 

Assume a classifier denoted as $f$ with output dimensions $N$ that takes $\bold{X} \in \mathbb{R}^M$ as an input. The first step is to compute the forward derivative:
\begin{align*}
\triangledown f &= \frac{\partial f(\bold{X})}{\partial \bold{X}}\\
&= \frac{\partial f_j(\bold{X})}{\partial x_i} \ i \in 1..M,j\in 1..N
\end{align*}
This is essentially the Jacobian matrix of the function denoted by $f$. The computation of this forward derivative can be simplified using the chain rule. The next step is to compute the saliency map \cite{simonyan_deep_2013} based on the forward derivative. The saliency map shows which input features are most important in determining the output.
\begin{align*}
\text{For $i \in 1..M$ and $t$ as target output}\\
S(\bold{X},t) [i] = 
\begin{cases}
0 \ \text{if} \ \frac{\partial f_t(\bold{X})}{\bold{X}_i}<0 \ \text{or} \sum_{j \neq t} \frac{\partial f_j(\bold{X})}{\bold{X}_i} > 0\\
\\
\Big(\frac{\partial f_t(\bold{X})}{\bold{X}_i}\Big)\Big\vert \sum_{j \neq t} \frac{\partial f_j(\bold{X})}{\bold{X}_i} \Big \vert \ \text{otherwise}
\end{cases}
\end{align*}
From the saliency map we identify the input $x_i$ that has the highest impact on the target output and perturb it by parameter $theta$ that is problem specific. This process is repeated iteratively and the maximum iteration is determined by the distortion limit $\gamma$. The distortion limit is manually set at the boundary at which humans can observe the distortion and is problem specific.
\item DeepFool - 
\item Carlini and Wagner - Carlini and Wagner introduce a strong set of attacks based on the $L_0$, $L_2$ and $L_inf$ distance \cite{carlini_towards_2016}. The problem for adversarial attacks is formulated the same was as Szegedy et al. \cite{szegedy_intriguing_2013}. The classifier is denoted as $C$ with input $x$:
\begin{align*}
\text{Minimize} \ D(x,x+\delta) + c. f(x + \delta) \\
\text{such that} \ x + \delta \in [0,1]^n
\end{align*}

Here $D$ is a distance function that is either the $L_0$, $L_2$ or $L$ norm and $f$ is an objective that simplifies the problem such that:
\begin{align*}
C(x + \delta) &= t \ \text{is true if} \ f(x + \delta) \leq 0\\
f(x') &= (max(Z(x')_i) - Z(x')_t)^+ \ i \neq t
\end{align*}
In the equation for $f$, $Z$ denotes the penultimate layer of the classifier, i.e the softmax values and $t$ is the target class. This is just one example of a the function $f$ many other functions work and can be found in the paper \cite{carlini_towards_2016}. Carlini and Wagner \cite{carlini_towards_2016} take care of the box constraint issue on $x + \delta$ by changing the variables with the substitution:
\begin{align*}
\delta_i = \frac{1}{2}(tanh(w_i) + 1) - x_i
\end{align*}

\end{enumerate}

\subsection{Properties of adversarial attacks}
In this section we'll highlight a few interesting properties of adversarial attacks which highlight the risk and importance of studying them in more detail.
\begin{enumerate}
\item Transferability of attacks - Papernot, Mcdaniel and Goodfellow \cite{papernot_transferability_2016} showed that adversarial examples are transferrable between machine learning models that use the same technique. They went one step further and showed that the models don't need to be using the same technique but still have transferrable adversarial examples. Liu et al. \cite{liu_delving_2016} showed that untargeted attacks are more transferrable than targeted attacks. In addition, they used an ensemble of models to create stronger adversarial attacks. Moosavi-Dezfooli et al. \cite{moosavi-dezfooli_universal_2016} created a universal perturbation that are image and network agnostic.
\item Real world attacks - Research has shown that adversarial examples are not limited to the digital world of finely crafted adverseries. Kurakin, Goodfellow and Bengio \cite{kurakin_adversarial_2016} showed that by printing and taking a photo of an adversarial example there are a significant number of cases for which it remains an adversary. Athalye et al. \cite{athalye_synthesizing_2017} created a framework in which objects can be rendered in 3-D and be printed and serve as adversarial examples for. Finally, Eykholt et al. \cite{eykholt_robust_2017} developed and algorithm to create perturbations to generate adversarial examples that are physically realizable. 
\end{enumerate}
\subsection{Summary of defenses}

\begin{enumerate}
\item Adversarial Retraining - The goal of retraining is to retrain the base model in order to be more robust to adversarial examples. Defensive distillation is one of the most popular ideas for defenses, distillation was introduced by Hinton et al. \cite{hinton_distilling_2015} and adapted by Papernot et al. \cite{papernot_distillation_2015}. In the retraining process the network architecture is kept the same except the target labels are the soft labels from the base network. Grosse et al.\cite{grosse_statistical_2017} suggested a method where an additional class is added in the retraining process for adversarial examples. Metzen et al. \cite{metzen_detecting_2017} add a subnetwork stemming from some layer that produces an output that gives the probabiliy of an example being an adversary. This solution does not directly classify an input as adversarial but it allows for human intervention evrytime the network is confused about the input.

\item Principal Component Analysis (PCA) - PCA is a dimensionally reduction technique that maps an $N$ dimensional space into a smaller $M$ dimensional space, emphasizing the most important components in the data \cite{shlens_tutorial_2014}. Hendrycks and Gimpel \cite{hendrycks_early_2016} introduce a method of analyzing the lower components of PCA finding that they can be used to differentiate adversarial examples from real inputs. Bhagoji, Cullina and Mittal \cite{bhagoji_enhancing_2017} hypothesize that the dimensionality reduction of PCA causes noise reduction and use the reduced dimensions as an input to a classifier to determine whether an input is adversarial or not. Instead of applying PCA on the input directly Li and Li \cite{li_adversarial_2017} apply PCA on the convolutionaly layer outputs and using a cascade classifier \cite{viola_robust_nodate} to determine if the input is adversarial.

\item Statistical analysis - There are some techniques which try to look at statistical features of the input to identify whether they are adversarial examples. Grosse et al. \cite{grosse_statistical_2017} suggest a method that uses Maximum Mean Discrepancy (MMD) \cite{gretton_kernel_2012} which is a technique for statistical technique to determine whether two randomly drawn samples originate from the same distribution. Using this they determined whether an input was an adversary or not. Feinman et al. \cite{feinman_detecting_2017} suggest a method that uses kernel density estimates. According to them the kernel density estimates can be used to model the submanifolds of each class and separate the adversarial examples from the real inputs.
\end{enumerate}

\subsection{Adversarial attacks in audio}

Kereliuk, Sturm and Larsen \cite{kereliuk_deep_2015} applied the attacks developed by Szegedy et al. \cite{szegedy_intriguing_2013} to the GTZAN dataset \cite{gtzan}. The input to the deep learning models was magnitude spectrograms so the perturbations were performed on the magnitude spectrogram. To reconstruct the audio the phase was determined using the Griffin-Lim algorithm and using that information the audio was resynthesized. The results show that adversarial examples can be generated for music on these datasets however we can perceive the change in audio. 

A drawback of this paper is that it relies on audio reconstruction to observe differences in the audio and because the phase information has to be resynthesized from a lossy method it is not ideal. Gong and Poellbauer address this problem by suggesting an end-to-end method for generating audio adversarial examples by directly perturbing the raw audio.



\section{Research questions}
\begin{enumerate}
\item Implementing state of the art attack and defense algorithms for MIR tasks -
While different types of attack and defense methods have been implemented and compared side by side for computer vision the same has not been done in MIR. The differences in input (audio vs image), the differences in the tasks, the data pre-processing etc. could make the results of this study different in music compared to vision. Even if the results are the same it is still important to recreate them in music to enable further research into the area.

\item Verifying the properties of adversarial attacks in MIR tasks - 
Some of the interesting properties of adversarial attacks were highlighted in the Background section. It would be interesting to see how transferable audio adversaries are between models, if there exists a universal perturbation to generate adversaries, are there real world audio adversaries etc.

\item MIR specific properties - A quick glance at deep learning research in MIR will show that there is a large diversity of tasks in which deep learning is applied and even within a specific task and on a specific dataset there is large deviations in input representation. So it would be interesting to go one step further in terms of transferability of audio adversaries to see if they are transferable between different types of input representations and if they are transferable between related but different tasks (note onset detection vs fundamental pitch estimatation).
 
\item Adversarial attacks for generative/transformative models: Most of the existing literature has focused on generating adversaries for classification tasks. in classification it is quite clear what the goal of the adversary is. However, with the increasing popularity of generative and transformative models in music applications it is important to explore adversarial attacks on generative models to ensure that 

\item Multi-task learning as a defense against adversaries: The current understanding for the existence of adversarial examples is that deep learning models might be learning the most comprehensive set of features to define the input. The intent with exploring multi-task learning is that by having different output goals the model will be forced to learn a more complete set of features to explain the input.
\end{enumerate}


\section{Timeline}

\subsection{Project 1: Implementing existing attacks and defenses in MIR tasks}
The goal of this project is to bridge the gap between computer vision and music information retrieval on adversarial attacks and defenses. The dataset we are going to use is GTZAN  . GTZAN is a genre recognition dataset which contains 1000 tracks that are 30 seconds long each of 10 different genres. Genre recognition is one of the most popular tasks in music information retrieval with widespread commercial use. We can obtain different types of machine learning algorithms trained on genre recognition. In addition, previous work adversarial attacks in music used the GTZAN dataset to create adversarial examples \cite{kereliuk_deep_2015} so we can use it as a benchmark to compare our work. 

\begin{enumerate}
\item Month 10 to Month 12
\item ISMIR 2019 conference, if not ISMIR workshop 2019
\end{enumerate}
\subsection{Project 2: Testing on well defined MIR tasks}
In the introduction for this proposal we said that genre classification has opinion based truths. Genre is a subjective definition and what one person might classify as hard rock might be classified as metal by someone else. In addition to there being issues with genre as a label, research has shown that there are inherent problems with the GTZAN dataset \cite{}. Both of these qualities make GTZAN not ideal for testing adversarial algorithms. 

Instrument classification is an ideal task for creating adversarial examples because you can create a dataset with small number of well defined classes and a lot of examples per class.  NSynth \cite{nsynth2017} is a datset that contains a large collection of notes produced by different instruments. It is very useful for instrument classification because it is a dataset of monophonic clean sounds which means it should be easy to train a high accuracy classifier on this dataset. The IRMAS \cite{bosch2012comparison} dataset is an alternative to NSynth, but IRMAS is made for predominant instrument recognition so it contains a polyphonic mixture of instruments.

\begin{enumerate}
\item Month 11 to Month 14
\item ICASSP 2020, if not NeurIPS workshop 2019
\end{enumerate}

\subsection{Project 3: Verifying the properties of adversarial attacks for music}
The main properties that we want to test are as follows:
\begin{enumerate}
\item Transferability of adversaries between different deep learning models trained on the same dataset
\item Using an ensemble to create stronger adversaries
\item Transferability of adversaries between different datasets that have the same classes
\item Universal perturbation to generate adversaries easily
\item Robustness of adversaries to compression such as mp3
\item Robustness of adversaries to playing over the speaker and recording it
\end{enumerate}

There are a lot of interesting properties to verify. However, conducting experiments to verify all of these properties is going to take too long. By the time we start working on this project we hope to identify the most important properties to focus on, these will most likely be those properties that lead naturally into the next project on MIR specific properties of adversaries.

In order to do research on the properties of adversaries we require two or more datasets that have similar classes and two or more deep learning models trained on each dataset. 
\begin{enumerate}
\item Month 15 to Month 18
\item ISMIR 2020
\end{enumerate}
\subsection{Project 4: Identifying properties of adversarial examples in MIR}
Deep learning tasks in MIR have different types of inputs for the same tasks. Some deep learning models use raw audio, some use mel spectrograms, some use short time fourier transforms, some use constant -Q transforms etc. It would be interesting to see if adversarial examples generated on a model that uses one type of input works on a model with a different type of input. In effect, we woulbe be looking for transferability of adversaries between different input representations.

It would be interesting to see if music adversaries transfer across different MIR tasks. For example, if we generate an adversary for instrument classification and test it on pitch estimation will it still work as an adversary and vice versa. 
\subsection{Project 5: Multi-task learning as a defense}


\subsection{Project 6: Adversaries for generative and transformative music applications}

%second column of first page if using \IEEEpubid
%\IEEEpubidadjcol


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
\begin{table}[!t]
% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.3}
% \extrarowheight as needed to properly center the text within the cells
\caption{Timeline for the project}
\label{table_example}
\centering
% Some packages, such as MDW tools, offer better commands for making tables
% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{|c||c|c|c|}
\hline
\textbf{S no.} & \textbf{Week No.} & \textbf{Resaerch ideas} & \textbf{Goals}\\
\hline
\hline
1 & February 2019 & \makecell{Reimplement Kereliuk, Sturm and Larsen \cite{kereliuk_deep_2015} with a \\ tensorflow implementation of spectrogram extraction} &Observe differences in perturbing spectrogram vs raw audio\\
\hline
2 & February 2019 & \makecell{Repeat the previous experiments with different attack \\methodologies} & \makecell{Understand the most effective and least\\effective attacks for music}\\
\hline
3 & February 2019 &\makecell{Implement existing defense methodologies and test their \\effectivesness against these attacks}  & \makecell{Identify topics to focus on} \\
\hline
4 & February 2019 & &\\
\hline
2 & February 2019 & &\\
\hline
2 & February 2019 & &\\
\hline
2 & February 2019 & &\\
\hline
2 & February 2019 & &\\
\hline
2 & February 2019 & &\\
\hline
2 & February 2019 & &\\
\hline
2 & February 2019 & &\\
\hline
2 & February 2019 & &\\
\hline
\end{tabular}
\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.




\section{Conclusion}
Summarize the whole proposal





% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%



% use section* for acknowledgment
\section*{Acknowledgment}
I would like to thank Prof. Mark Sandler, Dr. Emmanouil Benetos, Dr. Ning Xu and Mr. SKoT McDonald for the help and support they have given in shaping my stage-0 report and developing a long term plan for my PhD. I also want to thank ROLI for giving me access to their facilities which help my research.



% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{plain}
\bibliography{adversarial-attacks.bib}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)


% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:


% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}